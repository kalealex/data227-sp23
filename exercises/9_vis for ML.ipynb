{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9: Visualization for ML Interpretability\n",
    "\n",
    "Here we are going to try using an out-of-the-box tool for some ML interpretability which supports some of the techniques we introduced in lecture.\n",
    "\n",
    "The tool we will try out today is [interpretML](https://github.com/interpretml/interpret/), an interpretability Python module maintained by Microsoft. See this [blog post](https://towardsdatascience.com/interpretml-another-way-to-explain-your-model-b7faf0a384f8) for an overview of the kinds of things you can do with interpretML, including code snippets that will be helpful for this exercise."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset\n",
    "\n",
    "For today's exercise, we'll be working with a dataset on emergency room visits and what factors predict whether a person is admitted or discharged. Before modeling this data, we need to do a bit of preprocessing. We provide this code since it's not the emphasis of our exercise.\n",
    "\n",
    "We'll start by loading the dataset. The original is over 500,000 records, but we share a subsampled version with 60,000 records on the course website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>dep_name</th>\n",
       "      <th>esi</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>race</th>\n",
       "      <th>lang</th>\n",
       "      <th>religion</th>\n",
       "      <th>...</th>\n",
       "      <th>cc_vaginaldischarge</th>\n",
       "      <th>cc_vaginalpain</th>\n",
       "      <th>cc_weakness</th>\n",
       "      <th>cc_wheezing</th>\n",
       "      <th>cc_withdrawal-alcohol</th>\n",
       "      <th>cc_woundcheck</th>\n",
       "      <th>cc_woundinfection</th>\n",
       "      <th>cc_woundre-evaluation</th>\n",
       "      <th>cc_wristinjury</th>\n",
       "      <th>cc_wristpain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280199</td>\n",
       "      <td>280200</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Other</td>\n",
       "      <td>English</td>\n",
       "      <td>Catholic</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102688</td>\n",
       "      <td>102689</td>\n",
       "      <td>C</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>White or Caucasian</td>\n",
       "      <td>English</td>\n",
       "      <td>Catholic</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>143749</td>\n",
       "      <td>143750</td>\n",
       "      <td>B</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>English</td>\n",
       "      <td>Pentecostal</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>375544</td>\n",
       "      <td>375545</td>\n",
       "      <td>B</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Other</td>\n",
       "      <td>English</td>\n",
       "      <td>Pentecostal</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312621</td>\n",
       "      <td>312622</td>\n",
       "      <td>A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 974 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0 dep_name  esi   age  gender           ethnicity   \n",
       "0        280199      280200        A  2.0  48.0  Female  Hispanic or Latino  \\\n",
       "1        102688      102689        C  4.0  20.0  Female        Non-Hispanic   \n",
       "2        143749      143750        B  2.0  75.0  Female        Non-Hispanic   \n",
       "3        375544      375545        B  4.0  50.0  Female  Hispanic or Latino   \n",
       "4        312621      312622        A  4.0  26.0    Male        Non-Hispanic   \n",
       "\n",
       "                        race     lang     religion  ... cc_vaginaldischarge   \n",
       "0                      Other  English     Catholic  ...                 0.0  \\\n",
       "1         White or Caucasian  English     Catholic  ...                 0.0   \n",
       "2  Black or African American  English  Pentecostal  ...                 0.0   \n",
       "3                      Other  English  Pentecostal  ...                 0.0   \n",
       "4  Black or African American  English          NaN  ...                 0.0   \n",
       "\n",
       "  cc_vaginalpain cc_weakness cc_wheezing cc_withdrawal-alcohol cc_woundcheck   \n",
       "0            0.0         0.0         0.0                   0.0           0.0  \\\n",
       "1            0.0         0.0         0.0                   0.0           0.0   \n",
       "2            0.0         0.0         0.0                   0.0           0.0   \n",
       "3            0.0         0.0         0.0                   0.0           0.0   \n",
       "4            0.0         0.0         0.0                   0.0           0.0   \n",
       "\n",
       "  cc_woundinfection cc_woundre-evaluation cc_wristinjury  cc_wristpain  \n",
       "0               0.0                   0.0            0.0           0.0  \n",
       "1               0.0                   0.0            0.0           0.0  \n",
       "2               0.0                   0.0            0.0           0.0  \n",
       "3               0.0                   0.0            0.0           0.0  \n",
       "4               0.0                   0.0            0.0           0.0  \n",
       "\n",
       "[5 rows x 974 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# students may need to change this path to whereever they downloaded the data\n",
    "df = pd.read_csv(\"../data/hospital-admissions.csv\") \n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block of code handles some preprocessing, namely, relabeling strings in our dataset as integers. This is necessary for modeling the data, and the way we do it here preserves a connection between the original string values and their \"dummy coded\" integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import column_or_1d\n",
    "\n",
    "# set up for relabeling\n",
    "class MyLabelEncoder(LabelEncoder):\n",
    "\n",
    "    def fit(self, y):\n",
    "        y = column_or_1d(y, warn=True)\n",
    "        self.classes_ = pd.Series(y).unique()\n",
    "        return self\n",
    "\n",
    "def code_string(df, colname):\n",
    "    le = MyLabelEncoder()\n",
    "    arr = df[colname].values\n",
    "    le = le.fit(arr)\n",
    "    df[colname] = le.transform(arr)\n",
    "\n",
    "    return (df, le)\n",
    "\n",
    "RECODE_SET = ['disposition', 'dep_name', 'gender', 'ethnicity', 'race', 'lang', 'religion', 'maritalstatus', 'employstatus', 'insurance_status', 'arrivalmode', 'previousdispo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset:\n",
    "# eliminate timeseries variables\n",
    "for var in ['arrivalmonth', 'arrivalday', 'arrivalhour_bin']:\n",
    "    df.pop(var)\n",
    "# TODO: normalize X values?\n",
    "# make sure discharge maps to 0 when we use MyLabelEncoder\n",
    "df.sort_values(by = 'disposition', ascending = True) \n",
    "# call label encoder to code strings as numbers for modeling\n",
    "label_encoders = {}\n",
    "for var in RECODE_SET:\n",
    "    df, label_encoders[var] = code_string(df, var)\n",
    "# separate features and target\n",
    "y = df.pop('disposition').values\n",
    "X = df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Let's do the typical modeling workflow. I want you to try since the syntax is concise, and this is something you'll probably need to do often as a data scientist.\n",
    "\n",
    "We'll start by using scikit-learn's test-train split, which is described well in this [blog post](https://www.sharpsightlabs.com/blog/scikit-train_test_split/). For our case, we already have clean input data separated into features `X` and classification labels `y`. \n",
    "\n",
    "All you need to do is:\n",
    "\n",
    "- Filter the features in `X` to only those that you would like to include in the model. You should pick 10 features to use as predictors in the model.\n",
    "- Pass `X` and `y` to `sklearn.model_selection.test_train_split`\n",
    "- Be sure to stratify on the outcome variable `y` so that the test and train sets have proportional numbers of people admitted to the emergency room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT: drop all but 10 features from X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT: split X, y into non-overlapping subsamples for testing and training our model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PROMPT: What columns of X did you keep to include as predictors in your model? Why did you want to include these in particular?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will fit a model to our training data. Let's use a type of GAM called an Explainable Boosting Machine (EBM). This is basically a Generalized Additive Model fit using a variation on decision trees. We'll use the classifier version of this model, `interpret.glassbox.ExplainableBoostingClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT: fit an EBM classifier to the training sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are going to see a warning about missing data. It's best not to ignore that in practice.\n",
    "\n",
    "Let's compute our test set accuracy using an AUC (Area Under the receiver operating characteristic Curve), which is a common measure of accuracy for classifiers. To do this, you'll need to use `sklearn.metrics.accuracy_score` (see [API documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT: compute test set accuracy as a percentage.\n",
    "# HINT: you'll need to round the output of ebm.predict() to get binary predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability!\n",
    "\n",
    "Now that we have a model fit to our data, we can use the interpretability tools provided by `interpretML` to explain what our model has learned. You'll need `interpret.show` along with the `ebm.explain_global()` and `ebm.explain_local()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT: generate interpret's interactive widget for global explanations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PROMPT: Look at the \"Summary\" of feature importance. What are the top three predictors? Do these make sense to you? Are they what you expected?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PROMPT: Look through the shape functions for the features you've chosen to include in the model. Describe one or two unexpected patterns learned by the model. Reflect a bit on whether interpreting these charts feels rigorous to you.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT: generate interpret's interactive widget for local explanations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PROMPT: Pick two cases in the test set to examine using the dropdown menu. These should be one case where the model performs well and one case where the model performs poorly. In each case, describe how the model makes its prediction, focusing on which features contribute very differently to the two predictions. Please note if anything about the explanation doesn't make sense to you such that it might undermine your trust in the model.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e483c1fea6ecdefb016f0859b347b6a22e661bb4e4061935aba42c6ab22ce13d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
